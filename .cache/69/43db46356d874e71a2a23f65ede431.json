{"id":"../node_modules/openai/resources/edits.js","dependencies":[{"name":"D:\\Licenta\\node_modules\\openai\\resources\\edits.js.map","includedInParent":true,"mtime":1715682778508},{"name":"D:\\Licenta\\node_modules\\openai\\src\\resources\\edits.ts","includedInParent":true,"mtime":1715682778549},{"name":"D:\\Licenta\\package.json","includedInParent":true,"mtime":1715682779160},{"name":"D:\\Licenta\\node_modules\\openai\\package.json","includedInParent":true,"mtime":1715682778500},{"name":"openai/resource","loc":{"line":5,"column":27,"index":182},"parent":"D:\\Licenta\\node_modules\\openai\\resources\\edits.js","resolved":"D:\\Licenta\\node_modules\\openai\\resource.js"}],"generated":{"js":"'use strict';\n// File generated from our OpenAPI spec by Stainless.\nObject.defineProperty(exports, '__esModule', { value: true });\nexports.Edits = void 0;\nconst resource_1 = require('openai/resource');\nclass Edits extends resource_1.APIResource {\n  /**\n   * Creates a new edit for the provided input, instruction, and parameters.\n   *\n   * @deprecated The Edits API is deprecated; please use Chat Completions instead.\n   *\n   * https://openai.com/blog/gpt-4-api-general-availability#deprecation-of-the-edits-api\n   */\n  create(body, options) {\n    return this.post('/edits', { body, ...options });\n  }\n}\nexports.Edits = Edits;\n(function (Edits) {})((Edits = exports.Edits || (exports.Edits = {})));\n\n"},"sourceMaps":{"js":{"version":3,"file":"edits.js","sourceRoot":"","sources":["../src/resources/edits.ts"],"names":[],"mappings":";AAAA,qDAAqD;;;AAGrD,8CAA8C;AAI9C,MAAa,KAAM,SAAQ,sBAAW;IACpC;;;;;;OAMG;IACH,MAAM,CAAC,IAAsB,EAAE,OAA6B;QAC1D,OAAO,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE,EAAE,IAAI,EAAE,GAAG,OAAO,EAAE,CAAC,CAAC;IACnD,CAAC;CACF;AAXD,sBAWC;AAsFD,WAAiB,KAAK;AAGtB,CAAC,EAHgB,KAAK,GAAL,aAAK,KAAL,aAAK,QAGrB","sourcesContent":["// File generated from our OpenAPI spec by Stainless.\n\nimport * as Core from '../core';\nimport { APIResource } from '../resource';\nimport * as Completions from './completions';\nimport * as API from './index';\n\nexport class Edits extends APIResource {\n  /**\n   * Creates a new edit for the provided input, instruction, and parameters.\n   *\n   * @deprecated The Edits API is deprecated; please use Chat Completions instead.\n   *\n   * https://openai.com/blog/gpt-4-api-general-availability#deprecation-of-the-edits-api\n   */\n  create(body: EditCreateParams, options?: Core.RequestOptions): Core.APIPromise<Edit> {\n    return this.post('/edits', { body, ...options });\n  }\n}\n\nexport interface Edit {\n  /**\n   * A list of edit choices. Can be more than one if `n` is greater than 1.\n   */\n  choices: Array<Edit.Choice>;\n\n  /**\n   * A unix timestamp of when the edit was created.\n   */\n  created: number;\n\n  /**\n   * The object type, which is always `edit`.\n   */\n  object: string;\n\n  /**\n   * Usage statistics for the completion request.\n   */\n  usage: Completions.CompletionUsage;\n}\n\nexport namespace Edit {\n  export interface Choice {\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, or `length` if the maximum\n     * number of tokens specified in the request was reached.\n     */\n    finish_reason: 'stop' | 'length';\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n\n    /**\n     * The edited result.\n     */\n    text: string;\n  }\n}\n\nexport interface EditCreateParams {\n  /**\n   * The instruction that tells the model how to edit the prompt.\n   */\n  instruction: string;\n\n  /**\n   * ID of the model to use. You can use the `text-davinci-edit-001` or\n   * `code-davinci-edit-001` model with this endpoint.\n   */\n  model: (string & {}) | 'text-davinci-edit-001' | 'code-davinci-edit-001';\n\n  /**\n   * The input text to use as a starting point for the edit.\n   */\n  input?: string | null;\n\n  /**\n   * How many edits to generate for the input and instruction.\n   */\n  n?: number | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   *\n   * We generally recommend altering this or `top_p` but not both.\n   */\n  temperature?: number | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace Edits {\n  export import Edit = API.Edit;\n  export import EditCreateParams = API.EditCreateParams;\n}\n"]}},"error":null,"hash":"30bd9d80d3d51d52317195d8cd2e9102","cacheData":{"env":{}}}