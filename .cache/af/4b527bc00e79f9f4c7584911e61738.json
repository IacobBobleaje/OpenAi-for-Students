{"id":"../node_modules/openai/resources/batches.js","dependencies":[{"name":"D:\\Licenta\\node_modules\\openai\\resources\\batches.js.map","includedInParent":true,"mtime":1715683698887},{"name":"D:\\Licenta\\node_modules\\openai\\src\\resources\\batches.ts","includedInParent":true,"mtime":1715683698954},{"name":"D:\\Licenta\\package.json","includedInParent":true,"mtime":1715683699049},{"name":"D:\\Licenta\\node_modules\\openai\\package.json","includedInParent":true,"mtime":1715683698824},{"name":"../resource.js","loc":{"line":28,"column":27,"index":1266},"parent":"D:\\Licenta\\node_modules\\openai\\resources\\batches.js","resolved":"D:\\Licenta\\node_modules\\openai\\resource.js"},{"name":"../core.js","loc":{"line":29,"column":23,"index":1308},"parent":"D:\\Licenta\\node_modules\\openai\\resources\\batches.js","resolved":"D:\\Licenta\\node_modules\\openai\\core.js"},{"name":"./batches.js","loc":{"line":30,"column":40,"index":1363},"parent":"D:\\Licenta\\node_modules\\openai\\resources\\batches.js","resolved":"D:\\Licenta\\node_modules\\openai\\resources\\batches.js"},{"name":"../pagination.js","loc":{"line":31,"column":29,"index":1410},"parent":"D:\\Licenta\\node_modules\\openai\\resources\\batches.js","resolved":"D:\\Licenta\\node_modules\\openai\\pagination.js"}],"generated":{"js":"\"use strict\";\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.BatchesPage = exports.Batches = void 0;\nconst resource_1 = require(\"../resource.js\");\nconst core_1 = require(\"../core.js\");\nconst BatchesAPI = __importStar(require(\"./batches.js\"));\nconst pagination_1 = require(\"../pagination.js\");\nclass Batches extends resource_1.APIResource {\n    /**\n     * Creates and executes a batch from an uploaded file of requests\n     */\n    create(body, options) {\n        return this._client.post('/batches', { body, ...options });\n    }\n    /**\n     * Retrieves a batch.\n     */\n    retrieve(batchId, options) {\n        return this._client.get(`/batches/${batchId}`, options);\n    }\n    list(query = {}, options) {\n        if ((0, core_1.isRequestOptions)(query)) {\n            return this.list({}, query);\n        }\n        return this._client.getAPIList('/batches', BatchesPage, { query, ...options });\n    }\n    /**\n     * Cancels an in-progress batch.\n     */\n    cancel(batchId, options) {\n        return this._client.post(`/batches/${batchId}/cancel`, options);\n    }\n}\nexports.Batches = Batches;\nclass BatchesPage extends pagination_1.CursorPage {\n}\nexports.BatchesPage = BatchesPage;\n(function (Batches) {\n    Batches.BatchesPage = BatchesAPI.BatchesPage;\n})(Batches = exports.Batches || (exports.Batches = {}));\n"},"sourceMaps":{"js":{"version":3,"file":"batches.js","sourceRoot":"","sources":["../src/resources/batches.ts"],"names":[],"mappings":";AAAA,sFAAsF;;;;;;;;;;;;;;;;;;;;;;;;;;AAGtF,6CAA0C;AAC1C,qCAA2C;AAC3C,yDAAwC;AACxC,iDAAkE;AAElE,MAAa,OAAQ,SAAQ,sBAAW;IACtC;;OAEG;IACH,MAAM,CAAC,IAAuB,EAAE,OAA6B;QAC3D,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,UAAU,EAAE,EAAE,IAAI,EAAE,GAAG,OAAO,EAAE,CAAC,CAAC;IAC7D,CAAC;IAED;;OAEG;IACH,QAAQ,CAAC,OAAe,EAAE,OAA6B;QACrD,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,YAAY,OAAO,EAAE,EAAE,OAAO,CAAC,CAAC;IAC1D,CAAC;IAOD,IAAI,CACF,QAA+C,EAAE,EACjD,OAA6B;QAE7B,IAAI,IAAA,uBAAgB,EAAC,KAAK,CAAC,EAAE;YAC3B,OAAO,IAAI,CAAC,IAAI,CAAC,EAAE,EAAE,KAAK,CAAC,CAAC;SAC7B;QACD,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC,UAAU,EAAE,WAAW,EAAE,EAAE,KAAK,EAAE,GAAG,OAAO,EAAE,CAAC,CAAC;IACjF,CAAC;IAED;;OAEG;IACH,MAAM,CAAC,OAAe,EAAE,OAA6B;QACnD,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,YAAY,OAAO,SAAS,EAAE,OAAO,CAAC,CAAC;IAClE,CAAC;CACF;AApCD,0BAoCC;AAED,MAAa,WAAY,SAAQ,uBAAiB;CAAG;AAArD,kCAAqD;AAmMrD,WAAiB,OAAO;IAIR,mBAAW,GAAG,UAAU,CAAC,WAAW,CAAC;AAGrD,CAAC,EAPgB,OAAO,GAAP,eAAO,KAAP,eAAO,QAOvB","sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../core';\nimport { APIResource } from '../resource';\nimport { isRequestOptions } from '../core';\nimport * as BatchesAPI from './batches';\nimport { CursorPage, type CursorPageParams } from '../pagination';\n\nexport class Batches extends APIResource {\n  /**\n   * Creates and executes a batch from an uploaded file of requests\n   */\n  create(body: BatchCreateParams, options?: Core.RequestOptions): Core.APIPromise<Batch> {\n    return this._client.post('/batches', { body, ...options });\n  }\n\n  /**\n   * Retrieves a batch.\n   */\n  retrieve(batchId: string, options?: Core.RequestOptions): Core.APIPromise<Batch> {\n    return this._client.get(`/batches/${batchId}`, options);\n  }\n\n  /**\n   * List your organization's batches.\n   */\n  list(query?: BatchListParams, options?: Core.RequestOptions): Core.PagePromise<BatchesPage, Batch>;\n  list(options?: Core.RequestOptions): Core.PagePromise<BatchesPage, Batch>;\n  list(\n    query: BatchListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<BatchesPage, Batch> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/batches', BatchesPage, { query, ...options });\n  }\n\n  /**\n   * Cancels an in-progress batch.\n   */\n  cancel(batchId: string, options?: Core.RequestOptions): Core.APIPromise<Batch> {\n    return this._client.post(`/batches/${batchId}/cancel`, options);\n  }\n}\n\nexport class BatchesPage extends CursorPage<Batch> {}\n\nexport interface Batch {\n  id: string;\n\n  /**\n   * The time frame within which the batch should be processed.\n   */\n  completion_window: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was created.\n   */\n  created_at: number;\n\n  /**\n   * The OpenAI API endpoint used by the batch.\n   */\n  endpoint: string;\n\n  /**\n   * The ID of the input file for the batch.\n   */\n  input_file_id: string;\n\n  /**\n   * The object type, which is always `batch`.\n   */\n  object: 'batch';\n\n  /**\n   * The current status of the batch.\n   */\n  status:\n    | 'validating'\n    | 'failed'\n    | 'in_progress'\n    | 'finalizing'\n    | 'completed'\n    | 'expired'\n    | 'cancelling'\n    | 'cancelled';\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was cancelled.\n   */\n  cancelled_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started cancelling.\n   */\n  cancelling_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was completed.\n   */\n  completed_at?: number;\n\n  /**\n   * The ID of the file containing the outputs of requests with errors.\n   */\n  error_file_id?: string;\n\n  errors?: Batch.Errors;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch expired.\n   */\n  expired_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch will expire.\n   */\n  expires_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch failed.\n   */\n  failed_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started finalizing.\n   */\n  finalizing_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started processing.\n   */\n  in_progress_at?: number;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the file containing the outputs of successfully executed requests.\n   */\n  output_file_id?: string;\n\n  /**\n   * The request counts for different statuses within the batch.\n   */\n  request_counts?: BatchRequestCounts;\n}\n\nexport namespace Batch {\n  export interface Errors {\n    data?: Array<BatchesAPI.BatchError>;\n\n    /**\n     * The object type, which is always `list`.\n     */\n    object?: string;\n  }\n}\n\nexport interface BatchError {\n  /**\n   * An error code identifying the error type.\n   */\n  code?: string;\n\n  /**\n   * The line number of the input file where the error occurred, if applicable.\n   */\n  line?: number | null;\n\n  /**\n   * A human-readable message providing more details about the error.\n   */\n  message?: string;\n\n  /**\n   * The name of the parameter that caused the error, if applicable.\n   */\n  param?: string | null;\n}\n\n/**\n * The request counts for different statuses within the batch.\n */\nexport interface BatchRequestCounts {\n  /**\n   * Number of requests that have been completed successfully.\n   */\n  completed: number;\n\n  /**\n   * Number of requests that have failed.\n   */\n  failed: number;\n\n  /**\n   * Total number of requests in the batch.\n   */\n  total: number;\n}\n\nexport interface BatchCreateParams {\n  /**\n   * The time frame within which the batch should be processed. Currently only `24h`\n   * is supported.\n   */\n  completion_window: '24h';\n\n  /**\n   * The endpoint to be used for all requests in the batch. Currently\n   * `/v1/chat/completions` and `/v1/embeddings` are supported.\n   */\n  endpoint: '/v1/chat/completions' | '/v1/embeddings';\n\n  /**\n   * The ID of an uploaded file that contains requests for the new batch.\n   *\n   * See [upload file](https://platform.openai.com/docs/api-reference/files/create)\n   * for how to upload a file.\n   *\n   * Your input file must be formatted as a\n   * [JSONL file](https://platform.openai.com/docs/api-reference/batch/requestInput),\n   * and must be uploaded with the purpose `batch`.\n   */\n  input_file_id: string;\n\n  /**\n   * Optional custom metadata for the batch.\n   */\n  metadata?: Record<string, string> | null;\n}\n\nexport interface BatchListParams extends CursorPageParams {}\n\nexport namespace Batches {\n  export import Batch = BatchesAPI.Batch;\n  export import BatchError = BatchesAPI.BatchError;\n  export import BatchRequestCounts = BatchesAPI.BatchRequestCounts;\n  export import BatchesPage = BatchesAPI.BatchesPage;\n  export import BatchCreateParams = BatchesAPI.BatchCreateParams;\n  export import BatchListParams = BatchesAPI.BatchListParams;\n}\n"]}},"error":null,"hash":"5ac989b909a38e598a7d05c994d9616d","cacheData":{"env":{}}}