{"id":"../node_modules/openai/resources/beta/vector-stores/files.js","dependencies":[{"name":"D:\\Licenta\\node_modules\\openai\\resources\\beta\\vector-stores\\files.js.map","includedInParent":true,"mtime":1715683698973},{"name":"D:\\Licenta\\node_modules\\openai\\src\\resources\\beta\\vector-stores\\files.ts","includedInParent":true,"mtime":1715683699030},{"name":"D:\\Licenta\\package.json","includedInParent":true,"mtime":1715683699049},{"name":"D:\\Licenta\\node_modules\\openai\\package.json","includedInParent":true,"mtime":1715683698824},{"name":"../../../resource.js","loc":{"line":28,"column":27,"index":1273},"parent":"D:\\Licenta\\node_modules\\openai\\resources\\beta\\vector-stores\\files.js","resolved":"D:\\Licenta\\node_modules\\openai\\resource.js"},{"name":"../../../core.js","loc":{"line":30,"column":23,"index":1365},"parent":"D:\\Licenta\\node_modules\\openai\\resources\\beta\\vector-stores\\files.js","resolved":"D:\\Licenta\\node_modules\\openai\\core.js"},{"name":"./files.js","loc":{"line":31,"column":38,"index":1424},"parent":"D:\\Licenta\\node_modules\\openai\\resources\\beta\\vector-stores\\files.js","resolved":"D:\\Licenta\\node_modules\\openai\\resources\\beta\\vector-stores\\files.js"},{"name":"../../../pagination.js","loc":{"line":32,"column":29,"index":1469},"parent":"D:\\Licenta\\node_modules\\openai\\resources\\beta\\vector-stores\\files.js","resolved":"D:\\Licenta\\node_modules\\openai\\pagination.js"}],"generated":{"js":"\"use strict\";\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.VectorStoreFilesPage = exports.Files = void 0;\nconst resource_1 = require(\"../../../resource.js\");\nconst core_1 = require(\"../../../core.js\");\nconst core_2 = require(\"../../../core.js\");\nconst FilesAPI = __importStar(require(\"./files.js\"));\nconst pagination_1 = require(\"../../../pagination.js\");\nclass Files extends resource_1.APIResource {\n    /**\n     * Create a vector store file by attaching a\n     * [File](https://platform.openai.com/docs/api-reference/files) to a\n     * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object).\n     */\n    create(vectorStoreId, body, options) {\n        return this._client.post(`/vector_stores/${vectorStoreId}/files`, {\n            body,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Retrieves a vector store file.\n     */\n    retrieve(vectorStoreId, fileId, options) {\n        return this._client.get(`/vector_stores/${vectorStoreId}/files/${fileId}`, {\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    list(vectorStoreId, query = {}, options) {\n        if ((0, core_1.isRequestOptions)(query)) {\n            return this.list(vectorStoreId, {}, query);\n        }\n        return this._client.getAPIList(`/vector_stores/${vectorStoreId}/files`, VectorStoreFilesPage, {\n            query,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Delete a vector store file. This will remove the file from the vector store but\n     * the file itself will not be deleted. To delete the file, use the\n     * [delete file](https://platform.openai.com/docs/api-reference/files/delete)\n     * endpoint.\n     */\n    del(vectorStoreId, fileId, options) {\n        return this._client.delete(`/vector_stores/${vectorStoreId}/files/${fileId}`, {\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Attach a file to the given vector store and wait for it to be processed.\n     */\n    async createAndPoll(vectorStoreId, body, options) {\n        const file = await this.create(vectorStoreId, body, options);\n        return await this.poll(vectorStoreId, file.id, options);\n    }\n    /**\n     * Wait for the vector store file to finish processing.\n     *\n     * Note: this will return even if the file failed to process, you need to check\n     * file.last_error and file.status to handle these cases\n     */\n    async poll(vectorStoreId, fileId, options) {\n        const headers = { ...options?.headers, 'X-Stainless-Poll-Helper': 'true' };\n        if (options?.pollIntervalMs) {\n            headers['X-Stainless-Custom-Poll-Interval'] = options.pollIntervalMs.toString();\n        }\n        while (true) {\n            const fileResponse = await this.retrieve(vectorStoreId, fileId, {\n                ...options,\n                headers,\n            }).withResponse();\n            const file = fileResponse.data;\n            switch (file.status) {\n                case 'in_progress':\n                    let sleepInterval = 5000;\n                    if (options?.pollIntervalMs) {\n                        sleepInterval = options.pollIntervalMs;\n                    }\n                    else {\n                        const headerInterval = fileResponse.response.headers.get('openai-poll-after-ms');\n                        if (headerInterval) {\n                            const headerIntervalMs = parseInt(headerInterval);\n                            if (!isNaN(headerIntervalMs)) {\n                                sleepInterval = headerIntervalMs;\n                            }\n                        }\n                    }\n                    await (0, core_2.sleep)(sleepInterval);\n                    break;\n                case 'failed':\n                case 'completed':\n                    return file;\n            }\n        }\n    }\n    /**\n     * Upload a file to the `files` API and then attach it to the given vector store.\n     *\n     * Note the file will be asynchronously processed (you can use the alternative\n     * polling helper method to wait for processing to complete).\n     */\n    async upload(vectorStoreId, file, options) {\n        const fileInfo = await this._client.files.create({ file: file, purpose: 'assistants' }, options);\n        return this.create(vectorStoreId, { file_id: fileInfo.id }, options);\n    }\n    /**\n     * Add a file to a vector store and poll until processing is complete.\n     */\n    async uploadAndPoll(vectorStoreId, file, options) {\n        const fileInfo = await this.upload(vectorStoreId, file, options);\n        return await this.poll(vectorStoreId, fileInfo.id, options);\n    }\n}\nexports.Files = Files;\nclass VectorStoreFilesPage extends pagination_1.CursorPage {\n}\nexports.VectorStoreFilesPage = VectorStoreFilesPage;\n(function (Files) {\n    Files.VectorStoreFilesPage = FilesAPI.VectorStoreFilesPage;\n})(Files = exports.Files || (exports.Files = {}));\n"},"sourceMaps":{"js":{"version":3,"file":"files.js","sourceRoot":"","sources":["../../../src/resources/beta/vector-stores/files.ts"],"names":[],"mappings":";AAAA,sFAAsF;;;;;;;;;;;;;;;;;;;;;;;;;;AAGtF,mDAAgD;AAChD,2CAAiD;AACjD,2CAAkD;AAClD,qDAAoC;AACpC,uDAAwE;AAExE,MAAa,KAAM,SAAQ,sBAAW;IACpC;;;;OAIG;IACH,MAAM,CACJ,aAAqB,EACrB,IAAsB,EACtB,OAA6B;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,kBAAkB,aAAa,QAAQ,EAAE;YAChE,IAAI;YACJ,GAAG,OAAO;YACV,OAAO,EAAE,EAAE,aAAa,EAAE,eAAe,EAAE,GAAG,OAAO,EAAE,OAAO,EAAE;SACjE,CAAC,CAAC;IACL,CAAC;IAED;;OAEG;IACH,QAAQ,CACN,aAAqB,EACrB,MAAc,EACd,OAA6B;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,kBAAkB,aAAa,UAAU,MAAM,EAAE,EAAE;YACzE,GAAG,OAAO;YACV,OAAO,EAAE,EAAE,aAAa,EAAE,eAAe,EAAE,GAAG,OAAO,EAAE,OAAO,EAAE;SACjE,CAAC,CAAC;IACL,CAAC;IAcD,IAAI,CACF,aAAqB,EACrB,QAA8C,EAAE,EAChD,OAA6B;QAE7B,IAAI,IAAA,uBAAgB,EAAC,KAAK,CAAC,EAAE;YAC3B,OAAO,IAAI,CAAC,IAAI,CAAC,aAAa,EAAE,EAAE,EAAE,KAAK,CAAC,CAAC;SAC5C;QACD,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC,kBAAkB,aAAa,QAAQ,EAAE,oBAAoB,EAAE;YAC5F,KAAK;YACL,GAAG,OAAO;YACV,OAAO,EAAE,EAAE,aAAa,EAAE,eAAe,EAAE,GAAG,OAAO,EAAE,OAAO,EAAE;SACjE,CAAC,CAAC;IACL,CAAC;IAED;;;;;OAKG;IACH,GAAG,CACD,aAAqB,EACrB,MAAc,EACd,OAA6B;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,kBAAkB,aAAa,UAAU,MAAM,EAAE,EAAE;YAC5E,GAAG,OAAO;YACV,OAAO,EAAE,EAAE,aAAa,EAAE,eAAe,EAAE,GAAG,OAAO,EAAE,OAAO,EAAE;SACjE,CAAC,CAAC;IACL,CAAC;IAED;;OAEG;IACH,KAAK,CAAC,aAAa,CACjB,aAAqB,EACrB,IAAsB,EACtB,OAA2D;QAE3D,MAAM,IAAI,GAAG,MAAM,IAAI,CAAC,MAAM,CAAC,aAAa,EAAE,IAAI,EAAE,OAAO,CAAC,CAAC;QAC7D,OAAO,MAAM,IAAI,CAAC,IAAI,CAAC,aAAa,EAAE,IAAI,CAAC,EAAE,EAAE,OAAO,CAAC,CAAC;IAC1D,CAAC;IAED;;;;;OAKG;IACH,KAAK,CAAC,IAAI,CACR,aAAqB,EACrB,MAAc,EACd,OAA2D;QAE3D,MAAM,OAAO,GAA8B,EAAE,GAAG,OAAO,EAAE,OAAO,EAAE,yBAAyB,EAAE,MAAM,EAAE,CAAC;QACtG,IAAI,OAAO,EAAE,cAAc,EAAE;YAC3B,OAAO,CAAC,kCAAkC,CAAC,GAAG,OAAO,CAAC,cAAc,CAAC,QAAQ,EAAE,CAAC;SACjF;QACD,OAAO,IAAI,EAAE;YACX,MAAM,YAAY,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,aAAa,EAAE,MAAM,EAAE;gBAC9D,GAAG,OAAO;gBACV,OAAO;aACR,CAAC,CAAC,YAAY,EAAE,CAAC;YAElB,MAAM,IAAI,GAAG,YAAY,CAAC,IAAI,CAAC;YAE/B,QAAQ,IAAI,CAAC,MAAM,EAAE;gBACnB,KAAK,aAAa;oBAChB,IAAI,aAAa,GAAG,IAAI,CAAC;oBAEzB,IAAI,OAAO,EAAE,cAAc,EAAE;wBAC3B,aAAa,GAAG,OAAO,CAAC,cAAc,CAAC;qBACxC;yBAAM;wBACL,MAAM,cAAc,GAAG,YAAY,CAAC,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC,sBAAsB,CAAC,CAAC;wBACjF,IAAI,cAAc,EAAE;4BAClB,MAAM,gBAAgB,GAAG,QAAQ,CAAC,cAAc,CAAC,CAAC;4BAClD,IAAI,CAAC,KAAK,CAAC,gBAAgB,CAAC,EAAE;gCAC5B,aAAa,GAAG,gBAAgB,CAAC;6BAClC;yBACF;qBACF;oBACD,MAAM,IAAA,YAAK,EAAC,aAAa,CAAC,CAAC;oBAC3B,MAAM;gBACR,KAAK,QAAQ,CAAC;gBACd,KAAK,WAAW;oBACd,OAAO,IAAI,CAAC;aACf;SACF;IACH,CAAC;IAED;;;;;OAKG;IACH,KAAK,CAAC,MAAM,CACV,aAAqB,EACrB,IAAgB,EAChB,OAA6B;QAE7B,MAAM,QAAQ,GAAG,MAAM,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC,MAAM,CAAC,EAAE,IAAI,EAAE,IAAI,EAAE,OAAO,EAAE,YAAY,EAAE,EAAE,OAAO,CAAC,CAAC;QACjG,OAAO,IAAI,CAAC,MAAM,CAAC,aAAa,EAAE,EAAE,OAAO,EAAE,QAAQ,CAAC,EAAE,EAAE,EAAE,OAAO,CAAC,CAAC;IACvE,CAAC;IAED;;OAEG;IACH,KAAK,CAAC,aAAa,CACjB,aAAqB,EACrB,IAAgB,EAChB,OAA2D;QAE3D,MAAM,QAAQ,GAAG,MAAM,IAAI,CAAC,MAAM,CAAC,aAAa,EAAE,IAAI,EAAE,OAAO,CAAC,CAAC;QACjE,OAAO,MAAM,IAAI,CAAC,IAAI,CAAC,aAAa,EAAE,QAAQ,CAAC,EAAE,EAAE,OAAO,CAAC,CAAC;IAC9D,CAAC;CACF;AAjKD,sBAiKC;AAED,MAAa,oBAAqB,SAAQ,uBAA2B;CAAG;AAAxE,oDAAwE;AAyGxE,WAAiB,KAAK;IAGN,0BAAoB,GAAG,QAAQ,CAAC,oBAAoB,CAAC;AAGrE,CAAC,EANgB,KAAK,GAAL,aAAK,KAAL,aAAK,QAMrB","sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../../core';\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport { sleep, Uploadable } from '../../../core';\nimport * as FilesAPI from './files';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class Files extends APIResource {\n  /**\n   * Create a vector store file by attaching a\n   * [File](https://platform.openai.com/docs/api-reference/files) to a\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object).\n   */\n  create(\n    vectorStoreId: string,\n    body: FileCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFile> {\n    return this._client.post(`/vector_stores/${vectorStoreId}/files`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves a vector store file.\n   */\n  retrieve(\n    vectorStoreId: string,\n    fileId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFile> {\n    return this._client.get(`/vector_stores/${vectorStoreId}/files/${fileId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of vector store files.\n   */\n  list(\n    vectorStoreId: string,\n    query?: FileListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, VectorStoreFile>;\n  list(\n    vectorStoreId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, VectorStoreFile>;\n  list(\n    vectorStoreId: string,\n    query: FileListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, VectorStoreFile> {\n    if (isRequestOptions(query)) {\n      return this.list(vectorStoreId, {}, query);\n    }\n    return this._client.getAPIList(`/vector_stores/${vectorStoreId}/files`, VectorStoreFilesPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Delete a vector store file. This will remove the file from the vector store but\n   * the file itself will not be deleted. To delete the file, use the\n   * [delete file](https://platform.openai.com/docs/api-reference/files/delete)\n   * endpoint.\n   */\n  del(\n    vectorStoreId: string,\n    fileId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFileDeleted> {\n    return this._client.delete(`/vector_stores/${vectorStoreId}/files/${fileId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Attach a file to the given vector store and wait for it to be processed.\n   */\n  async createAndPoll(\n    vectorStoreId: string,\n    body: FileCreateParams,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const file = await this.create(vectorStoreId, body, options);\n    return await this.poll(vectorStoreId, file.id, options);\n  }\n\n  /**\n   * Wait for the vector store file to finish processing.\n   *\n   * Note: this will return even if the file failed to process, you need to check\n   * file.last_error and file.status to handle these cases\n   */\n  async poll(\n    vectorStoreId: string,\n    fileId: string,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const headers: { [key: string]: string } = { ...options?.headers, 'X-Stainless-Poll-Helper': 'true' };\n    if (options?.pollIntervalMs) {\n      headers['X-Stainless-Custom-Poll-Interval'] = options.pollIntervalMs.toString();\n    }\n    while (true) {\n      const fileResponse = await this.retrieve(vectorStoreId, fileId, {\n        ...options,\n        headers,\n      }).withResponse();\n\n      const file = fileResponse.data;\n\n      switch (file.status) {\n        case 'in_progress':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = fileResponse.response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        case 'failed':\n        case 'completed':\n          return file;\n      }\n    }\n  }\n\n  /**\n   * Upload a file to the `files` API and then attach it to the given vector store.\n   *\n   * Note the file will be asynchronously processed (you can use the alternative\n   * polling helper method to wait for processing to complete).\n   */\n  async upload(\n    vectorStoreId: string,\n    file: Uploadable,\n    options?: Core.RequestOptions,\n  ): Promise<VectorStoreFile> {\n    const fileInfo = await this._client.files.create({ file: file, purpose: 'assistants' }, options);\n    return this.create(vectorStoreId, { file_id: fileInfo.id }, options);\n  }\n\n  /**\n   * Add a file to a vector store and poll until processing is complete.\n   */\n  async uploadAndPoll(\n    vectorStoreId: string,\n    file: Uploadable,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const fileInfo = await this.upload(vectorStoreId, file, options);\n    return await this.poll(vectorStoreId, fileInfo.id, options);\n  }\n}\n\nexport class VectorStoreFilesPage extends CursorPage<VectorStoreFile> {}\n\n/**\n * A list of files attached to a vector store.\n */\nexport interface VectorStoreFile {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store file was created.\n   */\n  created_at: number;\n\n  /**\n   * The last error associated with this vector store file. Will be `null` if there\n   * are no errors.\n   */\n  last_error: VectorStoreFile.LastError | null;\n\n  /**\n   * The object type, which is always `vector_store.file`.\n   */\n  object: 'vector_store.file';\n\n  /**\n   * The status of the vector store file, which can be either `in_progress`,\n   * `completed`, `cancelled`, or `failed`. The status `completed` indicates that the\n   * vector store file is ready for use.\n   */\n  status: 'in_progress' | 'completed' | 'cancelled' | 'failed';\n\n  /**\n   * The total vector store usage in bytes. Note that this may be different from the\n   * original file size.\n   */\n  usage_bytes: number;\n\n  /**\n   * The ID of the\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n   * that the [File](https://platform.openai.com/docs/api-reference/files) is\n   * attached to.\n   */\n  vector_store_id: string;\n}\n\nexport namespace VectorStoreFile {\n  /**\n   * The last error associated with this vector store file. Will be `null` if there\n   * are no errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error` or `rate_limit_exceeded`.\n     */\n    code: 'internal_error' | 'file_not_found' | 'parsing_error' | 'unhandled_mime_type';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n}\n\nexport interface VectorStoreFileDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'vector_store.file.deleted';\n}\n\nexport interface FileCreateParams {\n  /**\n   * A [File](https://platform.openai.com/docs/api-reference/files) ID that the\n   * vector store should use. Useful for tools like `file_search` that can access\n   * files.\n   */\n  file_id: string;\n}\n\nexport interface FileListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\n   * fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.\n   */\n  filter?: 'in_progress' | 'completed' | 'failed' | 'cancelled';\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport namespace Files {\n  export import VectorStoreFile = FilesAPI.VectorStoreFile;\n  export import VectorStoreFileDeleted = FilesAPI.VectorStoreFileDeleted;\n  export import VectorStoreFilesPage = FilesAPI.VectorStoreFilesPage;\n  export import FileCreateParams = FilesAPI.FileCreateParams;\n  export import FileListParams = FilesAPI.FileListParams;\n}\n"]}},"error":null,"hash":"76e760c8e22286c3d2b1de8654bc0fd0","cacheData":{"env":{}}}